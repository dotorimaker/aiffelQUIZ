{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bd84bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# 1-12. load_wine: 와인을 분류해 봅시다. [1]\n",
    "################################################\n",
    "\n",
    "# (1) 필요한 모듈 import\n",
    "from sklearn.tree import DecisionTreeClassifier # 싸이킷런에 있는 결정트리분류기를 사용하기 위해 불러오는 코드\n",
    "# from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위해 쓰는 코드\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# (2) 데이터 준비\n",
    "wine = load_wine() #wine 데이터 전체를 불러온다.\n",
    "wine_data = wine.data #wine데이터의 data컬럼을 분류해 wine_data 변수에 담는다. #feature\n",
    "\n",
    "#wine데이터의 target컬럼을 분류해 wine_label 변수에 담는다. #label\n",
    "wine_label = wine.target \n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
    "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다. (어떤 값을 넣어도 무방하다.)\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7) \n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) #결정트리분류기의 객체를 만든다.\n",
    "decision_tree.fit(X_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
    "y_pred = decision_tree.predict(X_test) # 훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인한다.\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f4b6c040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [2]\n",
    "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위해 import\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, # wine 데이터의 data 컬럼\n",
    "                                                    wine_label, # wine 데이터의 target 컬럼\n",
    "                                                    test_size=0.2, # test_size : train data와 test data를 몇대몇으로 나눌지 정하는 옵션\n",
    "                                                    random_state=21) # random_state : 랜덤 패턴의 값을 지정\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
    "random_forest.fit(X_train, y_train) # 훈련\n",
    "y_pred = random_forest.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d3c702ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# [3]\n",
    "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
    "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
    "\n",
    "print(svm_model._estimator_type) # 이 모델이 어떤 타입인지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f8e36654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83        15\n",
      "           1       0.45      1.00      0.62        10\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.44      0.60      0.48        36\n",
      "weighted avg       0.48      0.61      0.52        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# [4]\n",
    "svm_model.fit(X_train, y_train) # 훈련\n",
    "y_pred = svm_model.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4cc9d62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# [5]\n",
    "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
    "sgd_model = SGDClassifier() # 모델 객체 생성\n",
    "\n",
    "print(sgd_model._estimator_type) # 이 모델의 타입을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "270351b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80        15\n",
      "           1       0.45      0.50      0.48        10\n",
      "           2       0.33      0.45      0.38        11\n",
      "\n",
      "    accuracy                           0.56        36\n",
      "   macro avg       0.60      0.54      0.55        36\n",
      "weighted avg       0.64      0.56      0.58        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [6]\n",
    "sgd_model.fit(X_train, y_train) # sgd모델로 훈련데이터로 훈련시킨다.\n",
    "y_pred = sgd_model.predict(X_test)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4852f062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# [7]\n",
    "from sklearn.linear_model import LogisticRegression # 선형분류기인 LogisticRegression를 사용하기 위한 import\n",
    "logistic_model = LogisticRegression() # 모델 객체 생성\n",
    "\n",
    "print(logistic_model._estimator_type) # 이 모델의 타입을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dca38528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# [8]\n",
    "logistic_model.fit(X_train, y_train) #LogisticRegression모델로 훈련데이터를 가지고 훈련시킨다.\n",
    "y_pred = logistic_model.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bb93bd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "# 1-11. load_digits\n",
    "################################################\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits() # Dictionary 자료형과 유사한 sklearn.utils.Bunch 자료형 \n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2e7e78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_data = digits.data\n",
    "digits_data.shape  # (손글씨 이미지의 개수, 이미지 당 Pixel 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bb4f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (1) 필요한 모듈 import\n",
    "from sklearn.tree import DecisionTreeClassifier # 싸이킷런에 있는 결정트리분류기를 사용하기 위해 불러오는 코드\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report #싸이킷런에 있는 분류 결과에 대한 시각화를 위해 쓰는 코드\n",
    "\n",
    "# (2) 데이터 준비\n",
    "digits = load_digits() #load_digits 데이터 전체를 불러온다.\n",
    "digits_data = digits.data #digits데이터의 data컬럼을 분류해 digits_data 변수에 담는다.\n",
    "digits_label = digits.target #digits데이터의 target컬럼을 분류해 digits_label 변수에 담는다.\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
    "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다. (어떤 값을 넣어도 무방하다.)\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7) \n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) #결정트리분류기의 객체를 만든다.\n",
    "decision_tree.fit(X_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
    "y_pred = decision_tree.predict(X_test) # 훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인한다.\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d25afc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.98      0.98      0.98        41\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       1.00      0.98      0.99        46\n",
      "           6       1.00      0.97      0.98        32\n",
      "           7       0.98      1.00      0.99        40\n",
      "           8       0.93      0.98      0.95        42\n",
      "           9       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [2]\n",
    "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위해 import\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, # digits 데이터의 data 컬럼\n",
    "                                                    digits_label, # digits 데이터의 target 컬럼\n",
    "                                                    test_size=0.2, # test_size : train data와 test data를 몇대몇으로 나눌지 정하는 옵션\n",
    "                                                    random_state=21) # random_state : 랜덤 패턴의 값을 지정\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
    "random_forest.fit(X_train, y_train) # 훈련\n",
    "y_pred = random_forest.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0fb6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "73197cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.95      1.00      0.97        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.97      1.00      0.98        32\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.98      0.95      0.96        42\n",
      "           9       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [3]\n",
    "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
    "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
    "\n",
    "print(svm_model._estimator_type) # 이 모델이 어떤 타입인지 확인한다.\n",
    "\n",
    "# [4]\n",
    "# 코드를 입력하세요\n",
    "svm_model.fit(X_train, y_train) # 훈련\n",
    "y_pred = svm_model.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccdf74d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d4b9425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.97      0.89      0.93        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.95      0.95      0.95        41\n",
      "           4       1.00      1.00      1.00        32\n",
      "           5       0.96      1.00      0.98        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       1.00      0.93      0.96        40\n",
      "           8       0.87      0.98      0.92        42\n",
      "           9       0.90      0.90      0.90        29\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.96      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [5]\n",
    "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
    "sgd_model = SGDClassifier() # 모델 객체 생성\n",
    "\n",
    "print(sgd_model._estimator_type) # 이 모델의 타입을 확인\n",
    "\n",
    "# [6]\n",
    "sgd_model.fit(X_train, y_train) # sgd모델로 훈련데이터로 훈련시킨다.\n",
    "y_pred = sgd_model.predict(X_test)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69942a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d9bf82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       0.98      0.98      0.98        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       0.97      0.97      0.97        40\n",
      "           8       1.00      0.95      0.98        42\n",
      "           9       0.96      0.93      0.95        29\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# [7]\n",
    "from sklearn.linear_model import LogisticRegression # 선형분류기인 LogisticRegression를 사용하기 위한 import\n",
    "logistic_model = LogisticRegression() # 모델 객체 생성\n",
    "\n",
    "print(logistic_model._estimator_type) # 이 모델의 타입을 확인\n",
    "\n",
    "# [8]\n",
    "logistic_model.fit(X_train, y_train) #LogisticRegression모델로 훈련데이터를 가지고 훈련시킨다.\n",
    "y_pred = logistic_model.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006361a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "800d7882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "# 1-13. load_breast_cancer\n",
    "################################################\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cancer = load_breast_cancer() # Dictionary 자료형과 유사한 sklearn.utils.Bunch 자료형 \n",
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ff48d06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_data = cancer.data\n",
    "cancer_data.shape  # (손글씨 이미지의 개수, 이미지 당 Pixel 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8282bf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (2) 데이터 준비\n",
    "\n",
    "cancer_label = cancer.target #wine데이터의 target컬럼을 분류해 wine_label 변수에 담는다.\n",
    "\n",
    "# (3) train, test 데이터 분리\n",
    "#train_test_split()를 사용하여 X값, y값을 각각 train data와 test data로 나눈다. 함수에 들어 갈 파라미터로는 x,y가 들어가고\n",
    "#test_size는 몇대몇으로 나눌지 정하는 옵션, random_state는 랜덤 패턴의 값을 지정한다. (어떤 값을 넣어도 무방하다.)\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data, \n",
    "                                                    cancer_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=7) \n",
    "\n",
    "\n",
    "# (4) 모델 학습 및 예측\n",
    "# DecisionTree 사용해 보기\n",
    "decision_tree = DecisionTreeClassifier(random_state=32) #결정트리분류기의 객체를 만든다.\n",
    "decision_tree.fit(X_train, y_train) # 분류기에 x와 y의 훈련 데이터를 넣어 훈련 시킨다.\n",
    "y_pred = decision_tree.predict(X_test) # 훈련된 분류기에 X_test라는 테스트 데이터셋을 넣어 얼마나 예측했는지 확인한다.\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과를 지표로 확인하기 위해 classification_report를 활용해 y_test, y_pred 값을 넣어 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "193faeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        32\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.98      0.98      0.98        41\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       1.00      0.98      0.99        46\n",
      "           6       1.00      0.97      0.98        32\n",
      "           7       0.98      1.00      0.99        40\n",
      "           8       0.93      0.98      0.95        42\n",
      "           9       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.98      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # RandomForest사용해 보기\n",
    "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트라는 분류기를 사용하기 위해 import\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, # digits 데이터의 data 컬럼\n",
    "                                                    digits_label, # digits 데이터의 target 컬럼\n",
    "                                                    test_size=0.2, # test_size : train data와 test data를 몇대몇으로 나눌지 정하는 옵션\n",
    "                                                    random_state=21) # random_state : 랜덤 패턴의 값을 지정\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32) # RandomForest분류기 객체를 생성\n",
    "random_forest.fit(X_train, y_train) # 훈련\n",
    "y_pred = random_forest.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57c2d1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        32\n",
      "           1       0.95      1.00      0.97        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       1.00      1.00      1.00        41\n",
      "           4       0.97      1.00      0.98        32\n",
      "           5       0.98      1.00      0.99        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       1.00      1.00      1.00        40\n",
      "           8       0.98      0.95      0.96        42\n",
      "           9       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM 사용해 보기\n",
    "from sklearn import svm #Support Vector Machine을 사용하기 위해 import\n",
    "svm_model = svm.SVC() # 모델 객체를 만든다.\n",
    "\n",
    "print(svm_model._estimator_type) # 이 모델이 어떤 타입인지 확인한다.\n",
    "\n",
    "\n",
    "# 코드를 입력하세요\n",
    "svm_model.fit(X_train, y_train) # 훈련\n",
    "y_pred = svm_model.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2608f52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "# [5] SGD Classifier 사용해 보기\n",
    "from sklearn.linear_model import SGDClassifier #선형분류기인 SGDClassifier를 사용하기 위한 import\n",
    "sgd_model = SGDClassifier() # 모델 객체 생성\n",
    "\n",
    "print(sgd_model._estimator_type) # 이 모델의 타입을 확인\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f9ff2247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        32\n",
      "           1       0.85      0.92      0.88        36\n",
      "           2       1.00      0.93      0.97        30\n",
      "           3       0.87      0.98      0.92        41\n",
      "           4       0.97      0.97      0.97        32\n",
      "           5       0.94      1.00      0.97        46\n",
      "           6       0.91      1.00      0.96        32\n",
      "           7       0.95      1.00      0.98        40\n",
      "           8       1.00      0.81      0.89        42\n",
      "           9       1.00      0.86      0.93        29\n",
      "\n",
      "    accuracy                           0.94       360\n",
      "   macro avg       0.95      0.94      0.94       360\n",
      "weighted avg       0.95      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# [6]\n",
    "sgd_model.fit(X_train, y_train) # sgd모델로 훈련데이터로 훈련시킨다.\n",
    "y_pred = sgd_model.predict(X_test)# 그 모델로 test데이터를 사용해 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "60550409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        32\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       0.94      0.97      0.95        32\n",
      "           5       0.98      0.98      0.98        46\n",
      "           6       1.00      1.00      1.00        32\n",
      "           7       0.97      0.97      0.97        40\n",
      "           8       1.00      0.95      0.98        42\n",
      "           9       0.96      0.93      0.95        29\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# [7] Logistic Regression 사용해보기\n",
    "from sklearn.linear_model import LogisticRegression # 선형분류기인 LogisticRegression를 사용하기 위한 import\n",
    "logistic_model = LogisticRegression() # 모델 객체 생성\n",
    "\n",
    "print(logistic_model._estimator_type) # 이 모델의 타입을 확인\n",
    "\n",
    "# [8]\n",
    "logistic_model.fit(X_train, y_train) #LogisticRegression모델로 훈련데이터를 가지고 훈련시킨다.\n",
    "y_pred = logistic_model.predict(X_test) # 예측\n",
    "\n",
    "print(classification_report(y_test, y_pred)) # 결과 지표를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf81b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트를 통한 깨달음\n",
    "breast_cancer 에서는 음성인데, 양성으로 판단하는 경우가 적은 것은 물론이지만,\n",
    "특히 양성인데 음성으로 판단하는 경우에 주의해야 합니다. 양성을 놓치는 경우 환자의 생명에 위험이 될 수 있는\n",
    "심각한 오판의 가능성의 심각성을 알아야 합니다.(FN)에 해당하는 실제 환자에게 음성판정하는 것을 주의.\n",
    "따라서, 암 환자를 진단하는 모델인 이경우에는 Precision, Recall 중 Recall이 매우 중요하다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
